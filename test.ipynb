{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer,AutoModelForSeq2SeqLM,TrainingArguments,Trainer,DataCollatorForLanguageModeling,TextDataset\n",
    "from peft import LoraConfig,TaskType,get_peft_model\n",
    "from datasets import load_dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r = 32,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "model_id = 'openai-community/gpt2'\n",
    "training_args = TrainingArguments (\n",
    "    output_dir='output/test',\n",
    "    learning_rate=1e-3,\n",
    "    per_device_eval_batch_size=32,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='no',\n",
    "    save_strategy='epoch',\n",
    "    #load_best_model_at_end='True',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "model = get_peft_model(model,peft_config)\n",
    "model.print_trainable_parameters()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_path = 'intents.json'):\n",
    "    with open(input_path,'r') as file:\n",
    "        data = json.load(file)\n",
    "    preprocess_data = []\n",
    "    for intent in data['intents']:\n",
    "        for patternn in intent['patterns']:\n",
    "            preprocess_data.append(f'User: {patternn}\\n')\n",
    "            for response in intent['responses']:\n",
    "                preprocess_data.append(f'Assistant: {response}\\n')\n",
    "    return ''.join(preprocess_data)\n",
    "def save_preprocess(data,output_path = 'data/data.txt'):\n",
    "    with open(output_path,'w') as file:\n",
    "        file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess()\n",
    "save_preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path='data/data.txt',\n",
    "    block_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args=  training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"output_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = AutoModelForCausalLM.from_pretrained(\"output_dir\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
