Warning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats. at C:\Users\Anh\.conda\envs\seminar\Lib\site-packages\torch\cuda\memory.py:330
Warning: 1Torch was not compiled with flash attention. (Triggered internally at ..\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:263.) at C:\Users\Anh\.conda\envs\seminar\Lib\site-packages\transformers\models\gemma\modeling_gemma.py:573
Warning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True) at C:\Users\Anh\.conda\envs\seminar\Lib\site-packages\accelerate\accelerator.py:432
Warning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants. at C:\Users\Anh\.conda\envs\seminar\Lib\site-packages\torch\utils\checkpoint.py:460
Warning: Could not find a config file in D:\Programming\Storage\Class\Project_F\model\gemma2b - will assume that the vocabulary was not modified. at C:\Users\Anh\.conda\envs\seminar\Lib\site-packages\peft\utils\save_and_load.py:154
